# Programming languages for distributed computing systems
<br>

**Programming languages for distributed computing systems** <br>
Henri E. Bal, Jennifer G. Steiner, Andrew S. Tanenbaum <br>
ACM Computing Surveys (CSUR), Volume 21, Issue 3 Pages 261 - 322 <br>

- https://doi.org/10.1145/72551.72552
<br>
<br>

## 분산 시스템 (Distributed System)
- 정의
  
  공통 주기억 장치를 공유하지 않는 독립적인 다수의 프로세서로 구성되며, <br>
  이들은 통신 네트워크를 통해 메시지를 주고받으며 협력한다.

- 통신 네트워크에 따라 밀접 결합 ~ 느슨한 결합으로 나눌 수 있다.

분산 시스템은 매우 다양한 종류의 애플리케이션에 사용된다. <br>
애플리케이션을 분산 시스템에서 구현하려는 이유는 크게 네 가지 범주로 나눌 수 있다:
1. 단일 계산의 처리 시간을 줄이기 위해  (병렬 고성능)
2. 신뢰성과 가용성을 높이기 위해  (장애 허용)
3. 시스템의 일부를 이용하여 특수한 기능을 제공하기 위해
4. 애플리케이션 자체가 본질적으로 분산되어 있기 때문에

- 물리적 분리 vs 공유 메모리
  
![image](https://github.com/user-attachments/assets/6ba5f3d8-60da-445d-a348-f9c25b0ecc26) <br>
(a) physical communication by message passing

메시지를 전달하기 위한 다양한 종류의 네트워크(예: 하이퍼큐브, LAN, WAN 등)가 존재하지만, <br>
물리적 특성은 다르더라도 모두 "프로세서 간 메시지를 전달하는 매체"라는 공통된 모델에 속한다.

![image](https://github.com/user-attachments/assets/c8bcd7da-3755-45ce-8d17-add7e537e6f4) <br>
(b) physical communication through shared memory

---

## 분산 프로그래밍 (Distributed Programming)
- 정의

  애플리케이션들을 분산 아키텍처에서 구현하는 활동

- 분산 프로그래밍 vs 순차 프로그래밍(Sequential Programming) <br>
구별되는 세 가지 특징
1. 병렬성
2. 통신
3. 부분 실패

- 분산 프로그래밍의 요구 사항

1. 프로그램의 서로 다른 부분을 서로 다른 프로세서에서 실행할 수 있도록 배정하는 능력
2. 프로세스들이 서로 통신하고 동기화할 수 있도록 하는 능력
3. 시스템의 부분 실패를 감지하고 복구 할 수 있는 능력

이러한 지원은 (분산) 운영체제가 제공할 수도 있고, <br>
>  라이브러리 루틴이 확장된 순차 언어로 작성 (but 순차 언어 자체가 부적합) <br>
> 복잡한 데이터 타입을 네트워크로 보낼 때 프로그래머가 직접 바이트로 바꾸고 다시 복원 <br>

분산 프로그래밍을 위해 특별히 설계된 언어가 제공할 수도 있다. <br>
>  데이터 타입 변환 자동 수행 <br>
>  운영체제가 제공하는 메시지 전달 모델보다 더 높은 수준의 추상화된 프로그래밍 모델 제공 <br>
 <br>
  <br>
  
---

## 분산 프로그래밍 언어

분산 소프트웨어 개발자는 ... <br>
“특정 분산 컴퓨팅 시스템 위에 구현해야 할 특정 애플리케이션이 있을 때, 어떤 프로그래밍 언어를 사용해야 하는가?”

언어는 다음 두 조건을 만족할 경우 적합한 후보로 고려될 수 있다. 

(1) 해당 언어가 애플리케이션에 적합하고 <br>
(2) 주어진 하드웨어 위에서 합리적인 효율로 구현 가능해야 한다.

분산 프로그래밍을 위한 다양한 언어들이 등장하면서, 가장 적합한 언어를 선택하는 일이 점점 어려워졌다. <br>
특히, 각 언어가 기반하고 있는 모델들이 매우 다양하다는 점이 문제를 더 복잡하게 만든다.
<br>
### 병렬 실행 + 통신

- 기본적인 모델

  병렬로 실행되는 일련의 순차적 프로세스들이 메시지를 통해 통신하는 형태 <br>
  통신 네트워크로 연결된 여러 프로세서로 구성된 분산 아키텍처를 직접적으로 반영 <br>
  e.g.  CSP, Occam

기본 모델(프로세스 + 메시지 전달)은 많은 애플리케이션에서 필요한 기능을 충분히 제공 가능 <br>
하지만 어떤 애플리케이션에서 이 모델은 지나치게 저수준일 수 있다. <br>
→ 병렬성, 통신, 장애 처리를 위한 더 높은 수준의 추상화를 제공하는 다양한 대체 모델들이 고안 <br>


여러 연구자들은 명령형(알고리즘 기반) 언어가 병렬성을 다루는 데 적합하지 않다고 본다. <br>
“한 번에 한 단어씩 처리하는” 폰 노이만 병목 때문에 명령형 언어는 본질적으로 순차적이라고 주장 <br>
→ 병렬성이 본래부터 내재된 언어 (함수형, 논리형, 객체지향 언어)에서의 병렬성 연구 활발 <br>


또한, 메시지 전달을 기본 통신 수단으로 삼는 것에 만족하지 못한 연구자들은 <br>
하드웨어 통신 모델을 직접 반영하지 않는 새로운 통신 모델을 개발했다.

그 중 하나는 프로시저 호출의 일반화된 형태를 통해 프로세서가 통신하게 하는 것  <br>
    : Distributed Processes에서 사용

보다 근본적인 방식으로는, 공유 데이터를 기반으로 하는 통신 모델  <br>
    : 실제로는 분산된 시스템에서 구현되지만, 논리적으로는 분산되어 있지 않은 것처럼 동작
   
### --
이제 논리적 분산과 물리적 분산을 다음과 같이 구분하자: <br>
1. 물리적 분산 / 비분산 <br>
    - 물리적 분산: 여러 개의 물리적으로 분리된 컴퓨터(노드)가 네트워크로 연결된 시스템. <br>
      예: 인터넷 상의 서버들, 클러스터 컴퓨팅, 데이터센터의 분산 시스템 <br>

    - 물리적 비분산: 하나의 기기 또는 하나의 공유 메모리를 가진 멀티코어 시스템. <br>
      예: 데스크탑 컴퓨터, 멀티코어 CPU, 공유 메모리를 가진 멀티프로세서 <br>

2. 논리적 분산 / 비분산 <br>
    - 논리적 분산: 소프트웨어 프로세스들이 명시적인 메시지 전달(message passing) 로 통신함. <br>
      → 즉, 서로 독립적인 단위로 나뉘어 있으며, 공유 메모리 없이 동작하는 것처럼 보임. <br>

    - 논리적 비분산: 소프트웨어 프로세스들이 공유된 데이터/메모리 를 통해 통신함. <br>
      → 프로그램 내에서 모든 데이터가 공유되며 마치 하나의 공간에서 동작하는 것처럼 보임. <br>
 <br>

(1) 논리적 분산 + 물리적 분산 

    - 실제 분산 시스템, 네트워크로 연결된 여러 서버가 각자 독립된 프로세스를 실행하고, 메시지를 주고받음. 
    - 예시: 클러스터, 클라우드 서비스, Hypercube, LAN, WAN 기반 시스템 
    - 통신은 실제 네트워크를 통해 이루어짐 

(2) 논리적 분산 + 물리적 비분산 

    - 분산처럼 보이지만, 실제로는 하나의 컴퓨터 안에서 실행됨 
    - 예: 하나의 멀티코어 CPU에서 여러 프로세스가 독립적으로 동작하면서 메시지 전달을 공유 메모리로 흉내냄 
    - 교육용 시뮬레이터, 테스트 환경 등에서 흔히 사용됨 
    - 프로그램 구조는 분산 시스템처럼 짰지만, 실제 통신은 빠른 메모리 복사 등으로 처리됨 

(3) 논리적 비분산 + 물리적 분산 

    - 물리적으로는 여러 노드지만, 마치 공유 메모리를 쓰는 것처럼 프로그래밍함 
    - 예: 분산 Shared Memory 시스템 (DSM), Linda, Orca 
    - 프로그래머 입장에서는 분산이라는 사실을 숨김. 그냥 변수 공유하듯 사용. 
    - 시스템이 내부적으로 분산 환경을 감추고 동기화, 일관성 보장 등을 처리함 → 구현은 복잡함 

(4) 논리적 비분산 + 물리적 비분산 

    - 가장 단순한 형태. 하나의 시스템에서 여러 스레드가 공유 메모리를 통해 통신 
    - 예: 멀티스레드 프로그램, POSIX Threads, Java Threads 
    - 구현도 간단하고 효율적 

이 논문에서는 물리적으로 분산된 시스템을 위한 언어를 다룬다.  <br>
대부분의 언어는 논리적으로 분산된 모델에 기반을 두고 있으며,  일부 언어는 논리적으로 비분산된 구조를 제공한다. <br>
<br>
<br>
### 부분 실패

분산 프로그래밍 모델에서 병렬성과 통신 외에 중요한 세 번째 문제는 프로세서 장애(failure) 처리이다.   <br>
기본적인 장애 처리 방법은 장애 감지 메커니즘을 제공하는 것이다.  <br>
이 경우 프로그래머가 장애 이후 발생하는 문제들을 정리하고, 시스템을 일관된 상태로 복구해야 한다. <br>

프로그래머를 이러한 복잡한 작업에서 해방시키기 위해, 장애 복구를 더 쉽게 해주는 모델들이 제안되었다. <br>

1. 시스템이 장애를 완전히 숨겨줄 수 있어야 한다. →  실제로 구현된 바 있음(Borg 외, 1983)<br>
2. 프로그래머에게 고수준의 복구 메커니즘을 제공하여 중요한 프로세스나 데이터를 지정하고, <br>
     장애 이후 이를 어떻게 복원할지 명시할 수 있도록 한다. → 예: Argus, Aeolus
 <br>
  <br>
  
---
 <br>
분산 프로그래밍의 요구 사항

## 1. 병렬성

- 정의

  분산 시스템은 정의상 하나 이상의 프로세서를 포함하므로, <br>
  하나의 프로그램의 여러 부분이 동시에 실행될 수 있다. <br>
 <br>
 
- 진정한 병렬성 (True Parallelism)

어떤 프로그램이 네 개의 병렬 프로세스로 구성되어 있고  <br>
네 개 이상의 프로세서를 가진 분산 시스템에서 실행된다면,  <br>

네 개의 프로세스는 각각 다른 프로세서에서 진정한 병렬로 실행될 수 있다. <br>

- 의사 병렬성(pseudoparallelism)
  
같은 프로그램이 두 개의 프로세서만 있는 시스템에서 실행된다면,  <br>
두 개의 프로세스가 각각의 프로세서에 할당되어 실행된다.  <br>

각 프로세서는 두 개의 프로세스를 의사 병렬적으로 실행하게 되며,  <br>
특정 시점에는 최대 두 개의 프로세스만이 실제로 병렬 실행되고 있는 것이다. <br>

 <br>
 
어떤 프로그램은 병렬 처리를 해서 실행 속도를 줄이는 것이 목적일 수 있지만,  모든 분산 프로그램이 그런 것은 아니다. <br>

하지만 병렬 처리가 실제 시스템에서 일어나는 일을 정확하게 표현해줄 수 있기 때문에,  <br>
병렬성을 표현할 수 있는 능력은 여전히 중요 <br>
 <br>
 
## 2. 통신과 동기화

서로 다른 프로세서에서 병렬로 실행되는 프로그램 조각들이 어떻게 협력할 것인가

프로세스 간 통신(IPC: Interprocess Communication)의 표현 방식은 일반적으로 두 가지 범주로 나눌 수 있다:  <br>
공유 데이터(shared data)와 메시지 전달(message passing).  <br>
하지만 이 구분이 항상 명확한 것은 아니다.  <br>

언어가 제공하는 IPC 모델과 그 구현은 전혀 다를 수 있다는 점에 유의해야 한다.   <br>
특히 우리는 공유 메모리가 없는 시스템을 위한 언어에만 논의를 제한하므로,   <br>
공유 데이터 모델은 언어 구현 내에서 시뮬레이션되어야 한다.  <br>

### 메시지 전달 (Message Passing)  <br>

메시지 기반 상호작용에서 가장 기본적인 원시 연산은   <br>
한 프로세스(송신자)에서 다른 프로세스(수신자)로의 점대점 메시지 전송이다.

-  송신자  <br>
: 명시적으로 메시지를 전송하거나 원격 프로시저를 호출함으로써 상호작용을 시작

- 수신자  <br>
: 메시지를 명시적으로 또는 암묵적으로 받을 수 있다.

점대점 메시지 전달 시스템에서 주요 설계 문제는   <br>
동기식(synchronous)과 비동기식(asynchronous) 중 어떤 메시지 전달 방식을 선택할 것인가이다.

- 동기식 메시지 전달  <br>
: 수신자가 메시지를 수락할 때까지 송신자가 블로킹된다. 즉, 송신자와 수신자는 데이터를 교환할 뿐만 아니라 동기화도 된다.  <br>

- 비동기식 메시지 전달  <br>
: 송신자는 수신자가 수락할 준비가 되었는지 여부와 상관없이 메시지를 보낸 후 바로 실행을 계속한다.   <br>
(실제 구현에서는 메시지가 전송을 위한 복사가 완료될 때까지 송신자가 잠시 정지할 수도 있지만, 이는 의미론적으로 드러나지 않는다.)
 <br>

 ### 메시지 전달 모델 4가지
 
1. 점대점 메시지

2. 랑데부
3. RPC

4. 일대다 메시지

<br>

- 점대점 메시지
  
점대점(point-to-point) 메시지는 두 프로세스 간의 단방향 통신을 설정.<br>
그러나 프로세스 간의 많은 상호작용은 본질적으로 양방향이다.

예를 들어, 클라이언트/서버 모델에서는 클라이언트가 서버에게 서비스를 요청하고, <br>
서버로부터 결과가 반환될 때까지 기다린다.

이러한 동작은 두 개의 점대점 메시지를 이용하여 시뮬레이션할 수 있지만, <br>
더 높은 수준의 단일 구성 요소를 사용하는 것이 더 간편하고 구현 측면에서도 효율적이다.

그러한 구성 요소 두 가지가 랑데뷰(rendezvous) 와 원격 프로시저 호출(remote procedure call, RPC)<br>
<br>

- 원격 프로시저 호출 (RPC)

양방향 통신을 위한 또 다른 원시 연산(primitive)이다.  <br>
이는 일반적인 프로시저 호출과 유사하지만, 호출자(caller)와 수신자(receiver)가 서로 다른 프로세스라는 점이 다르다. <br>
RPC 역시 완전한 동기식 상호작용. <br>

    어떤 프로세스 S(클라이언트)가
    다른 프로세스 R(서버)에 있는 함수(P)를
    일반 함수 호출처럼 호출하면,
    
    S가 함수에 넣은 입력값이 R에게 전달되고,
    R은 그 값을 가지고 함수(P)를 실행한 뒤,
    결과값을 S에게 되돌려준다.

이 모든 과정은 우리가 일반적으로 사용하는 sum(3, 4) 같은 함수 호출처럼 쉽게 보이도록 감춰져 있다.  <br>
그래서 이를 "투명한(transparent) RPC"라고 부른다. <br>

RPC는 원래 같은 메모리 안에서 실행되도록 설계된 일반 함수 호출과 완전히 똑같이 만들 수는 없다.  <br>

왜냐하면: <br>
서로 다른 프로세스는 메모리를 공유하지 않기 때문 <br>
예를 들어, P(x)라고 할 때, x가 포인터나 참조이면 문제가 생김 <br>

포인터가 문제되는 이유: <br>
S가 보낸 포인터는 S의 메모리 주소를 가리키는데,  R은 그 메모리 주소를 모름 <br>
따라서 R이 포인터를 역참조(dereference) 하려면,  S에게 다시 물어봐야 함 → 추가 통신 발생. <br>

해결 방법: <br>
포인터가 가리키는 값을 복사해서 보내기 → 그러나 이건 미묘하게 의미가 다름 <br>
예: 어떤 큰 트리 구조의 "중간 노드"만 가리키는 포인터라면… 복사하기 어렵고 의미가 달라질 수 있다. <br>

결론: RPC는 완벽히 "일반 함수 호출" 같을 수는 없다. <br>
투명한 RPC는 쓰기 편하고 익숙하지만, <br>
포인터, 참조 호출 등 공유 메모리를 가정한 기능은 정확하게 구현하기 어렵거나 비효율적이다. <br>
따라서 약간 다른 방식(copy-in/copy-out)으로 처리하거나,  프로그래머가 이런 차이를 이해하고 사용해야 한다. <br>
 <br>
 <br>

---
## 분산 언어 분류

분산 시스템을 쉽게 프로그래밍할 수 있도록 만들어진 여러 언어들을 소개 <br>
이미 100개 이상의 언어가 알려져 있고, 실제로는 더 많을 수 있다. <br>

전체 언어들을 크게 두 종류로 나눈다: <br>

1. 논리적으로 분산된 언어

각 계산 단위(예: 프로세스)는 자기만의 메모리 공간을 가지고 있고, <br>
서로 메시지를 보내며 통신한다. <br>
따라서 프로그램 전체는 분산된 메모리 구조 <br>

2. 논리적으로 비분산된 언어

계산 단위들이 논리적으로 같은 메모리 공간을 사용한다. <br>
즉, 데이터를 공유 메모리처럼 사용해 통신한다. <br>
여기서 말하는 공유 메모리는 물리적 의미가 아니라 논리적인 개념이다. <br>
실제 구현은 물리적으로 분산된 시스템에서도 가능하다. <br>
 <br>
 <br>

### 논리적으로 분산된 언어

- 동기 메시지 전달: 메시지를 보낼 때, 상대가 받을 때까지 기다림 → CPS (Communicating Sequential Processes)
  
- 비동기 메시지 전달: 메시지를 보내고 바로 다음 작업 수행 → Occam

- 랑데부(rendezvous): 양쪽이 동시에 준비되어야 통신

- 원격 프로시저 호출(RPC): 원격에서 함수를 호출하고 결과를 받음 → Distributed Processes (DP)

- 다중 통신 원시 연산(multicast, broadcast 등)

- 객체 기반 통신: 프로세스 간이 아닌 객체 단위(데이터+동작)로 메시지 교환

- 원자적 트랜잭션: 실패 시 롤백되는 안전한 작업 단위
 <br>
 <br>

- Distributed Processes (DP)
  
Brinch Hansen의 Distributed Processes (DP) [1978]는 Concurrent Pascal [1975]의 후속 언어이다. <br>
이들 모두는 실시간 시스템 프로그래밍을 목표로 한다.  <br>
Concurrent Pascal에서는 모니터 기반 통신 방식을 사용했지만,  <br>
DP에서는 RPC를 통한 프로세스 간 통신을 사용한다. <br>
 <br>
 
- 객체 기반 언어

객체 기반 접근법은 순차 프로그래밍뿐 아니라 분산 애플리케이션 개발에도 점점 더 인기를 끌고 있다. <br>
대부분의 병렬 객체 기반 또는 객체지향 언어들(표 8 참조)은 각 객체에 병렬 프로세스를 할당함으로써 병렬성을 실현한다.  <br>
즉, 객체가 능동적(active) 컴포넌트가 된다.  <br>
이 방식은 Concurrent Smalltalk, CLIX, Emerald, 그리고액터 언어인 Act 1, Cantor, CSSA 등에서 사용된다. <br>
액터 언어 [Hewitt 1977; Agha 1986]는 객체를 정적 클래스가 아닌 동적으로 변화하는 계층 구조로 구성한다.

 
<br>
<br>
  
